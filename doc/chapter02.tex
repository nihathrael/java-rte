\section{Building our own RTE system}
In this section we describe our best RTE system.

\subsection{Considerations from the prior systems}
All prior systems turned out to be worse than the normal lemma matching, Which to this point was still our  best system
with a score of 63.25\%. We did not see any big potential in improving the basic lemma matching further, so we decided
to try to tune our machine learning matcher \textit{BasicMahoutMatcher} in the form of \textit{MahoutMatcher}. Our basic
idea was to use the best non-machine-learner systems as features for the machine learner, hoping this would give the
machine learner a good basis to work with.

\subsection{Implementation}
We already had the basic \textit{BasicMahoutMatcher} from part three, which we decided to tune. The base of this matcher
was the \textit{OnlineLogisticRegression} learning algorithm distributed with the Mahout machine-learning library. We
played around with all our basic matchers as features, but ended up only using a quite small subset in the final
version. Only 6 features were used:
\begin{itemize}
    \item Lemma Matching
    \item IDF Lemma Matching
    \item Lemma+POS Matching
    \item BleuScore
    \item Polarity
    \item WordNet Synonym Matching
\end{itemize}

For all features for which we had matchers (all except Polarity) we used the matchers estimate whether a text/hypothesis
pair was entailing or not as value, as this is already a convinient value between 0 and 1. All matchers except for
BleuScore already contain the Polarity measurement already as a sort of "death" criteria, where we set the estimate to
0 if the polarity doesn't match. We still use it as seperate feature, by setting the value to 1 if it matches and 0 if
it doesn't, this proved helpful (without polarity feature, the result was ~62.6\%).

As we were not happy with the results we were able to achieve with our basic set of matchers, we decided to implement
the WordNet library using JWI\footnote{JWI website:\url{http://projects.csail.mit.edu/jwi}} as access to WordNet and the
JavaSimLibrary\footnote{JavaSimLibrary website: \url{http://pertomed.spim.jussieu.fr/~lma/jsl/}} to calculate distances
on the WordNet graph. JavaSimLibrary provides implementations of the Lin and Jiang \& Conrath measures.

We implemented three different matchers based on WordNet:
\begin{itemize}
    \item WordNetDistanceMatching
    \item LinSimilarityMatching
    \item SynonymMatching
\end{itemize} 

The \textit{WordNetDistanceMatching} recognizer uses the Jiang and Conrath distance and calculates the average distance
between all the words in a sentence, normalized with the hypothesis size.

The \textit{LinSimilarityMatching} uses the Lin similarity measurement. In contrast to the
\textit{WordNetDistanceMatching} the \textit{LinSimilarityMatching} does not calculate averages, instead it is an
implementation of the \textit{BasicMatcher} class, and returns whether two nodes in the graph match by checking if there
similarity is bigger than 0.8. This value was found by trying different values.

The \textit{SynonymMatching} is also a \textit{BasicMatcher} that checks whether two graph nodes have a overlap in synonyms
with 1 graph level depth.

\subsection{Where our system failed}
One example where our system failed was:
\begin{quote}
<t>In Nigeria, by far the most populous country in sub-Saharan Africa, over 2.7 million people are infected with HIV.</t>

<h>2.7 percent of the people infected with HIV live in Africa.</h>
\end{quote}
We assume this happenend because there are many words in the hypothesis that also occur in the text, this giving a good
lemma match for example. Polarity also matches, thus this is of no help. We do not see how our measurements could have
detected this as not being an entailment.


Another example:
\begin{quote}
<t>Rockweed has been harvested commercially in Nova Scotia since the late 1950's and is currently the most important commercial seaweed in Atlantic Canada.</t>

<h>Marine vegetation is  harvested.</h>
\end{quote}
Here the first two words of the hypothesis care not found in the text, thus leading to e.g. a very bad lemma matching. A
deeper synonyms analysis might help in this case. Other WordNet methodes like word stem could be useful as well.



